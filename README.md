# FOIA Web Crawler

A recursive web crawler built with Scrapy to extract and download PDF documents from U.S. government FOIA reading room pages.

## ğŸ” Features

- Starts from a list of FOIA agency URLs (e.g., TSA, ICE)
- Recursively follows internal links (up to 3 levels deep)
- Detects and downloads PDF files
- Automatically saves files into agency-specific folders
- Easy to expand for additional agencies

## ğŸ“‚ Project Structure

foia_web_crawler/
â”œâ”€â”€ scrapy.cfg
â”œâ”€â”€ foia_web_crawler/
â”‚ â”œâ”€â”€ items.py
â”‚ â”œâ”€â”€ middlewares.py
â”‚ â”œâ”€â”€ pipelines.py
â”‚ â”œâ”€â”€ settings.py
â”‚ â””â”€â”€ spiders/
â”‚ â””â”€â”€ foia_spider.py

1. Clone the repo:
   ```bash
   git clone https://github.com/Matt-Collman/foia_web_crawler.git
   cd foia_web_crawler

